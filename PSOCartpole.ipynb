{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimisation for solving the Cartpole Problem\n",
    "\n",
    "In this implementation, we use PSO to optimise the weights of the linear function approximator that's used to create the policy for the cartpole.v1 environment.\n",
    "\n",
    "This method manages to solver the environment in 3.0 iterations (on average). This makes it highly competitive with the far more advanced implementations found on the leaderboard. However, you could make a case for saying that this algorithm requires 30 iterations (on average) to solve as we candidate solutions in the form of the swarm. Regardless, the lack of DNN and gradient calculations cause this implementation to find extremely quickly.\n",
    "\n",
    "For more details of this implementation see here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import envs\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create optimiser\n",
    "\n",
    "This is a standard version of PSO. It could be improved with parameters tunning, similar to that seen in learning rate optimisers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleSwarmOptimisation(object):\n",
    "    \n",
    "    def __init__(self, fitnessFunction, bounds, numParticles, omega, v, phiL, phiG):\n",
    "        self.bestGlobalFitness = -np.inf              \n",
    "        self.bestGlobalPos = []     \n",
    "        self.fitnessFunction = fitnessFunction\n",
    "        self.bounds = bounds \n",
    "        self.swarm = [] #Create swarm\n",
    "        for i in range(numParticles):\n",
    "            self.swarm.append(Particle(bounds, omega, v, phiL, phiG))\n",
    "\n",
    "    def maxamise(self, maxIterations, target):\n",
    "        bestGlobalFitness = -np.inf              \n",
    "        bestGlobalPos = []                \n",
    "        #Optimization loop\n",
    "        for i in range(1, maxIterations):\n",
    "            #Evaluate each particles fitness\n",
    "            for p in self.swarm:\n",
    "                fitness = p.evaluate(self.fitnessFunction)\n",
    "                #Determine if current particle is new global best\n",
    "                if fitness > bestGlobalFitness:\n",
    "                    bestGlobalPos = p.bestPos.copy()\n",
    "                    bestGlobalFitness = p.bestFitness\n",
    "            #Update velocity and positions\n",
    "            for p in self.swarm:\n",
    "                p.updateVelocity(bestGlobalPos)\n",
    "                p.updatePosition(self.bounds)     \n",
    "            #Resample best to see if environment is solved\n",
    "            bestGlobalFitness = self.fitnessFunction(bestGlobalPos, 100)\n",
    "            print('Iteration: ' + str(i) + ' Global best: ' + str(bestGlobalFitness))\n",
    "            if bestGlobalFitness > target:\n",
    "                return i\n",
    "        return i #failed to solve\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, bounds, omega, v, phiL, phiG):\n",
    "        self.bestFitness = -np.inf     \n",
    "        self.bestPos = []\n",
    "        self.omega, self.phiL, self.phiG  = omega, phiL, phiG\n",
    "\n",
    "        self.position =  np.random.uniform(low=bounds[0], high=bounds[1], size=8)\n",
    "        self.velocity = np.random.uniform(low=-v, high=v, size=8)\n",
    "\n",
    "    # evaluate current fitness\n",
    "    def evaluate(self, fitnessFunction):\n",
    "        fitness = fitnessFunction(self.position, 25)\n",
    "        #update best position\n",
    "        if fitness > self.bestFitness:\n",
    "            self.bestPos = self.position.copy()\n",
    "            self.bestFitness = fitness\n",
    "        else:\n",
    "            #Re-evaluate best \n",
    "            self.bestFitness = fitnessFunction(self.bestPos, 25)\n",
    "        return self.bestFitness\n",
    "                    \n",
    "    # update new particle velocity\n",
    "    def updateVelocity(self, globalBest):\n",
    "        velLocal= self.phiL * np.random.rand((len(self.bestPos))) * (self.bestPos - self.position)\n",
    "        velGlobal = self.phiG * np.random.rand((len(self.bestPos))) * (globalBest - self.position)\n",
    "        self.velocity = self.omega * self.velocity + velLocal + velGlobal\n",
    "\n",
    "    # update the particle position \n",
    "    def updatePosition(self,bounds):  \n",
    "        self.position = self.position + self.velocity            \n",
    "        self.position[self.position < bounds[0]] = bounds[0]\n",
    "        self.position[self.position > bounds[1]] = bounds[1]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Fitness Function\n",
    "\n",
    "The particles position is used as the weights in a linear layer which is past through a softmax fuction to create a stochastic policy.\n",
    "\n",
    "Note the need for repeated sampling of the environment to get a good estimate of the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartpoleFitness(object):\n",
    "\n",
    "    def __init__(self, terminationStep):\n",
    "        self.env = gym.make('CartPole-v1')\n",
    "        self.terminationStep = terminationStep\n",
    "\n",
    "    def policy(self, state, pos):\n",
    "\t    z = state.dot(pos)\n",
    "\t    exp = np.exp(z)\n",
    "\t    return exp/np.sum(exp)\n",
    "\n",
    "    def evaluate(self, pos, evaluationIterations):\n",
    "        policy = np.reshape(pos, (4,2))\n",
    "        rewardTotal = 0\n",
    "        for i in range(evaluationIterations):\n",
    "            state = self.env.reset()\n",
    "            step = 0\n",
    "            while True:\n",
    "                step += 1\n",
    "                probs = self.policy(state, policy)\n",
    "                action = np.random.choice(2,p=probs)\n",
    "                state, reward, terminal, _ = self.env.step(action)\n",
    "                rewardTotal += reward\n",
    "                if terminal or step > self.terminationStep:\n",
    "                    break\n",
    "\n",
    "        return rewardTotal  / (i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment\n",
    "\n",
    "Change optimiser parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iteration: 1 Global best: 101.7\nIteration: 2 Global best: 164.81\nIteration: 3 Global best: 201.0\nTrail 1 solved in 3 iterations and 6.5 seconds.\nIteration: 1 Global best: 87.65\nIteration: 2 Global best: 105.42\nIteration: 3 Global best: 192.22\nIteration: 4 Global best: 198.77\nTrail 2 solved in 4 iterations and 7.9 seconds.\nIteration: 1 Global best: 136.89\nIteration: 2 Global best: 199.7\nTrail 3 solved in 2 iterations and 3.4 seconds.\nIteration: 1 Global best: 190.28\nIteration: 2 Global best: 201.0\nTrail 4 solved in 2 iterations and 5.1 seconds.\nIteration: 1 Global best: 135.67\nIteration: 2 Global best: 198.91\nTrail 5 solved in 2 iterations and 3.5 seconds.\nIteration: 1 Global best: 175.69\nIteration: 2 Global best: 186.95\nIteration: 3 Global best: 194.69\nIteration: 4 Global best: 200.39\nTrail 6 solved in 4 iterations and 12.7 seconds.\nIteration: 1 Global best: 86.83\nIteration: 2 Global best: 115.48\nIteration: 3 Global best: 146.22\nIteration: 4 Global best: 150.68\nIteration: 5 Global best: 201.0\nTrail 7 solved in 5 iterations and 10.0 seconds.\nIteration: 1 Global best: 74.17\nIteration: 2 Global best: 183.23\nIteration: 3 Global best: 199.54\nTrail 8 solved in 3 iterations and 4.6 seconds.\nIteration: 1 Global best: 145.19\nIteration: 2 Global best: 165.21\nIteration: 3 Global best: 192.11\nIteration: 4 Global best: 195.98\nTrail 9 solved in 4 iterations and 9.9 seconds.\nIteration: 1 Global best: 200.85\nTrail 10 solved in 1 iterations and 1.5 seconds.\nSolved in an average of 3.0 iterations, with an average of 6.5 seconds per trail.\n"
    }
   ],
   "source": [
    "cartpole = CartpoleFitness(200)\n",
    "\n",
    "weightSpaceBounds = 8\n",
    "numberOfParticles = 10\n",
    "momentum = 0.5\n",
    "initialVelocityBounds = 0.2\n",
    "localWeight = 2\n",
    "globalWeight = 2\n",
    "\n",
    "p = [weightSpaceBounds, numberOfParticles, momentum, initialVelocityBounds, localWeight, globalWeight]\n",
    "\n",
    "timeTotal = 0\n",
    "iterationTotal = 0\n",
    "for i in range(1, 11):\n",
    "    start = time.time()\n",
    "    solver = ParticleSwarmOptimisation(cartpole.evaluate, (-p[0],p[0]), p[1], p[2], p[3], p[4], p[5])\n",
    "    k = solver.maxamise(25, 195)\n",
    "    iterationTotal += k\n",
    "    end = time.time() - start\n",
    "    print('Trail ' + str(i) + ' solved in ' + str(k) + ' iterations and ' + \"{:.1f}\".format(end) + ' seconds.')\n",
    "    timeTotal += end\n",
    "print('Solved in an average of ' + str(iterationTotal/i) + ' iterations, with an average of ' + \"{:.1f}\".format(timeTotal /i) + ' seconds per trail.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the cartpole problem is solved in an average of 3.0 iterations, with an average of 6.5 seconds per trail.\n",
    "\n",
    "This average time could be greatly improved with the use of parallel computation and better hardware."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit47d146cc5c834d3aadd19303fc80d1ee",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}